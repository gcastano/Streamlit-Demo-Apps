# Importa las librer칤as necesarias
import streamlit as st  # Para la creaci칩n de la aplicaci칩n web
import pandas as pd  # Para la manipulaci칩n y an치lisis de datos
import numpy as np  # Para operaciones num칠ricas eficientes
import spacy  # Para el procesamiento del lenguaje natural (NLP)
from sklearn.feature_extraction.text import TfidfVectorizer  # Para convertir texto a vectores TF-IDF
# Ejemplo de TF-IDF
# https://remykarem.github.io/tfidf-demo/
from sklearn.metrics.pairwise import cosine_similarity  # Para calcular la similitud del coseno entre vectores

# Instala las librer칤as necesarias (si a칰n no lo has hecho)
# pip install streamlit pandas numpy spacy scikit-learn

# Configuraci칩n de la p치gina de Streamlit
st.set_page_config(
    page_title="B칰squeda de f칩rmulas de Excel",  # T칤tulo de la p치gina
    page_icon="游눹",  # Icono de la p치gina
    layout="wide",  # Dise침o de p치gina ancho para aprovechar al m치ximo el espacio
    initial_sidebar_state="expanded"  # Barra lateral expandida por defecto
)

# Lista de componentes de procesamiento de lenguaje natural (NLP) de spaCy que no se utilizar치n
# Estos componentes se desactivan para mejorar el rendimiento, ya que no son necesarios para esta tarea.
unwanted_pipes = ["ner", "parser"]

# Carga el modelo de lenguaje espa침ol de spaCy
# Este modelo se utiliza para tokenizar el texto y obtener las ra칤ces de las palabras (lemas).
nlp = spacy.load("es_core_news_sm")

# Funci칩n para tokenizar el texto utilizando spaCy
def spacy_tokenizer(doc):
    """
    Tokeniza el texto utilizando spaCy y realiza un procesamiento b치sico:

    1. Deshabilita los componentes de NLP no deseados (NER y an치lisis sint치ctico).
    2. Tokeniza el texto (lo divide en palabras y signos de puntuaci칩n).
    3. Obtiene el lema (ra칤z de la palabra) de cada token.
    4. Filtra los tokens para mantener solo palabras alfab칠ticas y eliminar signos de puntuaci칩n y espacios en blanco.

    Args:
        doc: El texto a tokenizar.

    Returns:
        Una lista de tokens (lemas) del texto.
    """
    with nlp.disable_pipes(*unwanted_pipes):
        return [t.lemma_ for t in nlp(doc) if not t.is_punct and not t.is_space and t.is_alpha]

# Funci칩n para generar las caracter칤sticas TF-IDF del corpus
@st.cache_resource  # Almacena en cach칠 el resultado de la funci칩n para mejorar el rendimiento
def generarFeatures(corpus):
    """
    Genera las caracter칤sticas TF-IDF del corpus:

    1. Crea un objeto TfidfVectorizer, que se utiliza para convertir una colecci칩n de documentos de texto en una matriz de caracter칤sticas TF-IDF.
    2. Ajusta el vectorizador al corpus (aprende el vocabulario y los pesos IDF).
    3. Transforma el corpus en una matriz TF-IDF, donde cada fila representa un documento y cada columna representa una palabra del vocabulario.

    Args:
        corpus: Una lista de documentos de texto.

    Returns:
        Una tupla que contiene:
            - La matriz de caracter칤sticas TF-IDF.
            - El objeto vectorizador TF-IDF.
    """
    vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)
    features = vectorizer.fit_transform(corpus)
    return features, vectorizer

# Funci칩n para obtener los 칤ndices de los k elementos principales de una matriz
def top_k(arr, k):
    """
    Devuelve los 칤ndices de los k elementos principales de una matriz.

    Args:
        arr: La matriz.
        k: El n칰mero de elementos principales a devolver.

    Returns:
        Una matriz NumPy que contiene los 칤ndices de los k elementos principales.
    """
    kth_largest = (k + 1) * -1
    return np.argsort(arr)[:kth_largest:-1]

# Carga los archivos CSV que contienen las f칩rmulas de Excel en espa침ol e ingl칠s
# Estos archivos deben estar en la misma carpeta que el script de Python.
dfFormulasES = pd.read_csv('excelformulasES.csv')
dfFormulasEN = pd.read_csv('excelformulasEN.csv')

# T칤tulo de la aplicaci칩n
st.header('B칰squeda de f칩rmulas de Excel')

# URLs de las fuentes de las f칩rmulas
URL_ES = "https://support.microsoft.com/es-es/office/funciones-de-excel-por-orden-alfab%C3%A9tico-b3944572-255d-4efb-bb96-c6d90033e188"
URL_EN = "https://support.microsoft.com/en-us/office/excel-functions-alphabetical-b3944572-255d-4efb-bb96-c6d90033e188"

# Muestra las URLs de las fuentes de las f칩rmulas
st.info(f"Formula Sources: [SPANISH]({URL_ES}), [ENGLISH]({URL_EN})")

# Selector de idioma
parIdioma = st.radio('Idioma / Language', options=['Espa침ol', 'English'], index=0, horizontal=True)

# Inicializa las variables en funci칩n del idioma seleccionado
if parIdioma == 'Espa침ol':
    dfFormulasES['corpus'] = dfFormulasES['descripcion'] + ' ' + dfFormulasES['formula']
    corpus = dfFormulasES['corpus'].values.astype('U')  # Convierte el texto a Unicode
    etiquetaBusqueda = 'Para qu칠 busca la f칩rmula'
    etiquetaBoton = 'Buscar'
    etiquetaCantResult = 'Cantidad de resultados'
    etiquetaNoEncontrado = 'No se encontraron f칩rmulas con las caracter칤sticas solicitadas: '
    dfFormulas = dfFormulasES
    tabs=['B칰squeda sem치ntica','Datos']
else:
    dfFormulasEN['corpus'] = dfFormulasEN['descripcion'] + ' ' + dfFormulasEN['formula']
    corpus = dfFormulasEN['corpus'].values.astype('U')
    etiquetaBusqueda = 'What kind of formula are you looking for?'
    etiquetaCantResult = 'Number of results'
    etiquetaBoton = 'Search'
    etiquetaNoEncontrado = 'No formulas were found with the characteristics: '
    dfFormulas = dfFormulasEN
    tabs=['Semantic Search','Data']

# Crea dos pesta침as: "B칰squeda sem치ntica" y "Datos"
tabBuscar,tabDatos = st.tabs(tabs)

# Contenido de la pesta침a "B칰squeda sem치ntica"
with tabBuscar:
    # Genera las caracter칤sticas TF-IDF del corpus
    features, vectorizer = generarFeatures(corpus)
        
    # Cuadro de texto para la b칰squeda
    parTexto = st.text_input(etiquetaBusqueda)

    # Control deslizante para seleccionar la cantidad de resultados
    parNumResult = st.number_input(etiquetaCantResult, min_value=5, max_value=20, value=10)

    # Bot칩n de b칰squeda
    btnBuscar = st.button(etiquetaBoton)

    # Cuando se presiona el bot칩n de b칰squeda
    if btnBuscar:
        # Procesa la consulta
        query = [parTexto]
        query_tfidf = vectorizer.transform(query) # Vectorizamos la consulta

        # Calcula la similitud del coseno entre la consulta y todas las f칩rmulas
        cosine_similarities = cosine_similarity(features, query_tfidf).flatten()        
        
        # Obtiene los 칤ndices de las f칩rmulas m치s similares
        top_related_indices = top_k(cosine_similarities, parNumResult)
        similarities = cosine_similarities[top_related_indices]        
        
        # Divide la p치gina en tres columnas
        cols = st.columns(3)
        i = 0
 
        # Muestra las f칩rmulas m치s similares        
        if similarities.sum() > 0:
            # Filtramos los items encontrados
            dfFormulasEncontradas =dfFormulas.iloc[top_related_indices]
            # Aplicamos los niveles de similitud
            dfFormulasEncontradas['similitud']=similarities
            
            # Itera sobre las f칩rmulas encontradas y las muestra en las columnas
            for index, fila in dfFormulasEncontradas.sort_values('similitud', ascending=False).iterrows():
                formula = fila['formula']
                nombreFormula = fila['nombreFormula']
                if formula != nombreFormula:
                    formula = f'{formula} / {nombreFormula}'
                sintaxis = fila['sintaxis'].replace('=', '')
                sintaxis = f'={sintaxis}'
                descripcion = fila['descripcion']
                similarity = fila['similitud']
                url = fila['url']
                categoria = fila['categoria']
                texto = f"""<div style='background-color:#F1FADA;margin:5px;padding:10px;border-radius:10px'>
                <a href='{url}'><h4>{formula}</h4></a><i>{categoria}</i><br />
                <code>{sintaxis}</code><br />
                {descripcion}</div>
                    """
                if similarity > 0:
                    if i == 3:
                        i = 0
                    col = cols[i]
                    col.write(texto, unsafe_allow_html=True)
                    col.progress(similarity, f"Similitud **:blue[{similarity:.2%}]**")
                    i = i + 1
        else:
            st.warning(f'{etiquetaNoEncontrado} **{parTexto}**')

# Contenido de la pesta침a "Datos"
with tabDatos:
    # Muestra el DataFrame con las f칩rmulas en una tabla interactiva
    st.dataframe(dfFormulas[['formula','nombreFormula', 'categoria', 'descripcion', 'sintaxis']],use_container_width=True)