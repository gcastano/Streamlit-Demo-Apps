# ==========================================
# üì¶ INSTALACI√ìN DE LIBRER√çAS NECESARIAS
# Ejecuta este comando en tu terminal antes de empezar:
# pip install streamlit pandas scikit-learn joblib
# ==========================================

import streamlit as st  # Librer√≠a para crear aplicaciones web de ciencia de datos r√°pidamente.
import pandas as pd  # La herramienta principal para manipulaci√≥n y an√°lisis de datos (DataFrames).
from sklearn.model_selection import train_test_split  # Para dividir datos en entrenamiento y prueba.
from sklearn.preprocessing import StandardScaler, OneHotEncoder  # Para escalar n√∫meros y convertir texto a n√∫meros.
from sklearn.impute import SimpleImputer  # Para rellenar datos faltantes (nulos).
from sklearn.compose import ColumnTransformer  # Para aplicar diferentes preprocesamientos a diferentes columnas.
from sklearn.linear_model import LogisticRegression  # El algoritmo de Machine Learning que usaremos.
from sklearn.pipeline import Pipeline  # Para encadenar pasos (limpieza -> procesamiento -> modelo) en un solo objeto.
from sklearn.metrics import accuracy_score, classification_report  # Para medir qu√© tan bueno es el modelo.
import joblib  # Para guardar el modelo entrenado en un archivo y usarlo despu√©s.

# Configuraci√≥n inicial de la p√°gina de Streamlit
st.set_page_config(page_title="Entrenamiento Modelo Salud Mental", page_icon="‚öôÔ∏è", layout="wide")

st.title("‚öôÔ∏è Entrenamiento del Modelo de Salud Mental")
st.write("""
Sube tu dataset (CSV) para entrenar el modelo de Regresi√≥n Log√≠stica. 
El sistema procesar√° los datos, entrenar√° la IA y te dar√° un reporte sobre su viabilidad.
""")

# 1. Cargar el dataset
# st.file_uploader permite al usuario subir archivos desde su navegador.
archivo_subido = st.file_uploader("Sube el archivo 'Mental_Health_Lifestyle_Dataset.csv'", type=["csv"])

if archivo_subido is not None:
    # ---------------------------------------------------------
    # PANDAS: Lectura de datos
    # `pd.read_csv` convierte el archivo CSV en un DataFrame de Pandas.
    # ---------------------------------------------------------
    df = pd.read_csv(archivo_subido)    
    st.success("¬°Archivo cargado correctamente!")
    
    with st.expander("Ver vista previa de los datos"):
        # PANDAS: Visualizaci√≥n preliminar
        # Rellenamos nulos solo para la vista previa visual, no afecta el entrenamiento a√∫n.
        df = df.fillna({'Mental Health Condition': 'Healthy'})        
        st.dataframe(df)
    
    # Bot√≥n para iniciar el entrenamiento
    if st.button("üöÄ Entrenar Modelo", type="primary"):
        with st.spinner('Procesando datos y entrenando el modelo...'):
            
            # 2. Limpieza b√°sica con Pandas
            # Verificamos si la columna objetivo existe.
            if 'Mental Health Condition' not in df.columns:
                st.error("El archivo no contiene la columna objetivo 'Mental Health Condition'.")
                st.stop()
            
            # PANDAS transformation: dropna
            # Eliminamos las filas donde no sabemos el diagn√≥stico (target).
            # En aprendizaje supervisado, no podemos entrenar sin la respuesta correcta.
            df = df.dropna(subset=['Mental Health Condition'])

            # 3. Separar caracter√≠sticas (X) y variable objetivo (y)
            # PANDAS transformation: drop y selecci√≥n de series
            # X = Todo menos la respuesta. y = Solo la respuesta.
            X = df.drop('Mental Health Condition', axis=1)
            y = df['Mental Health Condition']

            # Definici√≥n manual de listas de columnas para procesarlas por separado
            columnas_numericas = ['Age', 'Sleep Hours', 'Work Hours per Week', 
                                  'Screen Time per Day (Hours)', 'Social Interaction Score', 'Happiness Score']
            columnas_categoricas = ['Country', 'Gender', 'Exercise Level', 'Diet Type', 'Stress Level']

            # Validaci√≥n de columnas
            faltantes = [col for col in columnas_numericas + columnas_categoricas if col not in X.columns]
            if faltantes:
                st.error(f"Faltan las siguientes columnas en el dataset: {faltantes}")
                st.stop()

            # 4. Crear "Mini-Pipelines" para preprocesamiento
            # Un Pipeline asegura que las transformaciones se apliquen en orden exacto.
            
            # Pipeline Num√©rico:
            # 1. Imputer: Si falta un n√∫mero (NaN), pon la mediana de esa columna.
            # 2. Scaler: Normaliza los datos para que variables grandes (Salario) no opaquen a peque√±as (Edad).
            #            El Scaler deja los datos con media 0 y desviaci√≥n est√°ndar 1, lo que ayuda a la Regresi√≥n Log√≠stica a encontrar patrones m√°s f√°cilmente.
            # La Regresi√≥n Log√≠stica funciona mejor cuando las caracter√≠sticas num√©ricas est√°n en la misma escala.
            pipeline_numerico = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='median')),  
                ('scaler', StandardScaler())  
            ])

            # Pipeline Categ√≥rico:
            # 1. Imputer: Si falta texto, pon el valor m√°s repetido (moda).
            # 2. Encoder: Convierte texto ("Male", "Female") en n√∫meros binarios (0, 1) que la IA entienda.
            pipeline_categorico = Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('encoder', OneHotEncoder(handle_unknown='ignore'))  
            ])

            # 5. ColumnTransformer
            # Aplica el pipeline num√©rico a las cols num√©ricas y el categ√≥rico a las categ√≥ricas simult√°neamente.
            preprocesador = ColumnTransformer(
                transformers=[
                    ('num', pipeline_numerico, columnas_numericas),
                    ('cat', pipeline_categorico, columnas_categoricas)
                ])

            # Creaci√≥n del Pipeline Maestro
            # Une el preprocesador con el modelo final (Regresi√≥n Log√≠stica).
            modelo_pipeline = Pipeline(
                steps=[
                    # Paso 1: Aplicar el preprocesador (limpieza, imputaci√≥n, encoding)
                    ('preprocesador', preprocesador),
                    # Paso 2: Aplicar Regresi√≥n Log√≠stica con configuraci√≥n optimizada
                    ('clasificador', LogisticRegression(
                        # Maneja m√∫ltiples clases (m√°s de 2 categor√≠as de salud mental)
                        multi_class='multinomial',
                        # Algoritmo de optimizaci√≥n: mejor para problemas multiclase
                        solver='lbfgs',
                        # N√∫mero m√°ximo de iteraciones para la convergencia del modelo
                        max_iter=1000
                    ))
                ]
            )

            # 6. Dividir datos y Entrenar
            # train_test_split: Separa el 20% de los datos para examen final (test) y 80% para estudiar (train).
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # .fit(): Aqu√≠ ocurre la "magia". El modelo aprende los patrones matem√°ticos.
            modelo_pipeline.fit(X_train, y_train)

            # 7. Evaluar
            # .predict(): Ponemos a prueba el modelo con datos que nunca ha visto (X_test).
            y_pred = modelo_pipeline.predict(X_test)
            
            # M√©tricas de √©xito
            precision = accuracy_score(y_test, y_pred)
            reporte_dict = classification_report(y_test, y_pred, zero_division=0, output_dict=True)
            
            # Guardar el modelo usando Joblib
            # Esto crea un archivo binario .pkl que contiene toda la l√≥gica aprendida.
            archivo_modelo = 'modelo_salud_mental.pkl'
            joblib.dump(modelo_pipeline, archivo_modelo)

        # ---------------- RESULTADOS EN PANTALLA ----------------
        st.divider()
        st.header("üìä Resultados del Entrenamiento")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="Precisi√≥n del Modelo (Accuracy)", value=f"{precision * 100:.2f}%")
        
        with col2:
            st.success(f"üíæ El modelo se ha guardado exitosamente como `{archivo_modelo}`")

        st.subheader("Reporte de Clasificaci√≥n Detallado")
        # PANDAS: Transposici√≥n
        # Convertimos el diccionario del reporte a DataFrame y usamos .transpose() para rotarlo y leerlo mejor.
        df_reporte = pd.DataFrame(reporte_dict).transpose()
        st.dataframe(df_reporte.style.format("{:.2f}"))
        
        with st.expander("üìñ Explicaci√≥n de M√©tricas de Evaluaci√≥n del Modelo"):
            st.write("""
        - **Precisi√≥n (Precision)**: Indica la proporci√≥n de verdaderos positivos sobre el total de positivos predichos. Es √∫til cuando el costo de un falso positivo es alto. Un valor alto (cercano a 1) es deseable, mientras que un valor bajo indica que el modelo est√° haciendo muchas predicciones incorrectas.            
        - **Exhaustividad (Recall)**: Tambi√©n conocido como sensibilidad, mide la proporci√≥n de verdaderos positivos sobre el total de positivos reales. Es importante en contextos donde es cr√≠tico identificar todos los casos positivos. Un valor alto es bueno, mientras que un valor bajo sugiere que el modelo est√° perdiendo muchos casos positivos.            
        - **F1-Score**: Es la media arm√≥nica entre precisi√≥n y exhaustividad. Es √∫til cuando se necesita un balance entre ambas m√©tricas. Un F1-score alto indica un buen equilibrio entre precisi√≥n y recall, mientras que un bajo sugiere que el modelo no est√° funcionando bien en ninguno de los dos aspectos.            
        - **Support**: Representa el n√∫mero de ocurrencias de cada clase en el conjunto de datos. Es importante tener en cuenta el soporte al evaluar las m√©tricas, ya que un modelo puede tener un buen rendimiento en clases con alto soporte, pero un rendimiento deficiente en clases con bajo soporte.
        
        **Umbrales a considerar**:
        - Precisi√≥n y Recall: Valores por encima de 0.7 son generalmente considerados buenos, pero esto puede variar seg√∫n el contexto.
        - F1-Score: Un valor por encima de 0.6 es aceptable, mientras que por encima de 0.8 es excelente.
        """)
            
        # ---------------- EXPLICACI√ìN Y RECOMENDACI√ìN ----------------
        st.divider()
        st.header("üìù An√°lisis de Viabilidad del Modelo")
        
        # L√≥gica condicional simple para dar feedback al usuario sobre la calidad del modelo.
        if precision >= 0.85:
            st.success("""
            **VEREDICTO: ‚úÖ Altamente Recomendado para uso preliminar.**
            
            **Explicaci√≥n:** El modelo ha logrado una precisi√≥n excelente (mayor al 85%). Esto significa que ha encontrado patrones matem√°ticos fuertes y claros entre el estilo de vida del paciente y su diagn√≥stico de salud mental. Se puede utilizar como herramienta de apoyo (triaje cl√≠nico) con un alto grado de confianza, aunque siempre recordando que no reemplaza el criterio de un m√©dico.
            """)
        elif precision >= 0.65:
            st.warning("""
            **VEREDICTO: ‚ö†Ô∏è Utilizar con Precauci√≥n.**
            
            **Explicaci√≥n:** El modelo tiene un rendimiento aceptable/moderado (entre 65% y 85%). Ha encontrado algunos patrones √∫tiles, pero comete errores considerables. 
            
            *¬øSe puede usar?* S√≠, pero solo con fines experimentales, educativos o como una segunda opini√≥n muy superficial. Se recomienda conseguir m√°s datos (m√°s filas) o probar algoritmos m√°s complejos (como Random Forest o XGBoost) para mejorar esta precisi√≥n antes de llevarlo a un entorno cl√≠nico.
            """)
        else:
            st.error("""
            **VEREDICTO: ‚ùå NO recomendado para uso real.**
            
            **Explicaci√≥n:** La precisi√≥n obtenida es baja (menor al 65%). En problemas de salud, un modelo con esta precisi√≥n equivale casi a "adivinar" o equivocarse de forma constante. 
            
            *¬øPor qu√© ocurre esto?* 
            1. Es probable que no exista una correlaci√≥n lineal fuerte entre las variables (ej. comer comida chatarra no siempre equivale directamente a PTSD).
            2. La Regresi√≥n Log√≠stica es un modelo simple y los datos pueden ser demasiado complejos.
            
            *Conclusi√≥n:* **No utilices este modelo para predecir riesgos en pacientes reales.** Se necesita una limpieza profunda de datos, agregar nuevas variables m√©dicas o cambiar el tipo de Inteligencia Artificial.
            """)